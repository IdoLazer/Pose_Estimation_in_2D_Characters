Network:
        self.conv1 = nn.Conv2d(3, 4, 5)
        self.conv2 = nn.Conv2d(4, 5, 3)
        self.fc1 = nn.Linear(5 * ((((ImageGenerator.IMAGE_SIZE - 4) // 2) - 2) // 2) * (
                (((ImageGenerator.IMAGE_SIZE - 4) // 2) - 2) // 2), 32)
        self.fc2 = nn.Linear(32, 3 * num_layers)
        self.fc3 = nn.Linear(3 * num_layers, 6 * num_layers)
        torch.nn.init.xavier_uniform_(self.conv1.weight, 0.1)
        torch.nn.init.xavier_uniform_(self.conv2.weight, 0.1)
        torch.nn.init.xavier_uniform_(self.fc1.weight, 0.1)
        torch.nn.init.xavier_uniform_(self.fc2.weight, 0.1)
        torch.nn.init.xavier_uniform_(self.fc3.weight, 0.1)
        with torch.no_grad():
            bias = []
            for part in ImageGenerator.DRAWING_ORDER:
                bias += CANONICAL_BIAS_DICT[part]
            self.fc3.bias = torch.nn.Parameter(torch.DoubleTensor(bias).view(-1, 6 * num_layers))

Learning:
    kernel_sizes = [70, 50, 35, 25, 17, 13, 9, 7]
    optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.01)
    criterion = nn.MSELoss()
